{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trust metrics\n",
    "from itertools import combinations\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def cluster(pubid):\n",
    "    return network_data[network_data['pubid'] == pubid]\n",
    "\n",
    "def authname(authid):\n",
    "    return network_data[network_data['authid'] == authid]['author'].iloc[0]\n",
    "\n",
    "def edges(pubid):\n",
    "    pub_cluster = cluster(pubid)\n",
    "    authors = pub_cluster['authid'].unique()\n",
    "    weight = pub_cluster['type_weitght'].iloc[0]\n",
    "\n",
    "    return [(*edge, {'weight': weight, 'pubid': pubid}) for edge in combinations(authors, 2)]\n",
    "\n",
    "def path_length(path_weights, alpha):\n",
    "    return sum([1 / weight ** alpha for weight in path_weights])\n",
    "\n",
    "def jumps(l, n=2):\n",
    "    return [l[i:i+n] for i in range(len(l))][:-1]\n",
    "\n",
    "def sum_weights(n, j):\n",
    "    return sum([n[j[0]][j[1]][k]['weight'] for k in n[j[0]][j[1]]])\n",
    "\n",
    "def sum_of_weights(jumps, network):\n",
    "    return [sum_weights(network, jump) for jump in jumps]\n",
    "\n",
    "def deg_arr(deg):\n",
    "    return np.array([v for _, v in deg])\n",
    "\n",
    "def degree_centrality(network, alpha):\n",
    "    k = deg_arr(network.degree()) ** (1 - alpha)\n",
    "    s = deg_arr(network.degree(weight='weight')) ** alpha\n",
    "    centralities = k * s\n",
    "    return [{node: centralities[i]} for i, node in enumerate(network.nodes)]\n",
    "\n",
    "PUB_WEIGHTS = {\n",
    "  'Livro Publicado ou Organizado ': 9,\n",
    "  'Artigo Publicado': 8,\n",
    "  'Capítulo de Livro Publicado': 8,\n",
    "  'Artigo Aceito para Publicação': 7,\n",
    "  'Texto em Jornal/Revista': 6,\n",
    "  'Trabalho em Evento': 3,\n",
    "  'Outra Produção Bibliográfica': 2,\n",
    "  'Prefácio/Posfácio': 2,\n",
    "  'nan': 1\n",
    "}\n",
    "\n",
    "network_data = pd.read_csv('trust_network.csv')\n",
    "network_data['pub_type'] = network_data['pub_type'].astype(str)\n",
    "network_data['type_weitght'] = network_data.pub_type.apply(lambda p: PUB_WEIGHTS[p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "trust_network = nx.MultiGraph()\n",
    "\n",
    "for authid in network_data['authid'].unique():\n",
    "    trust_network.add_node(authid, name=authname(authid)) \n",
    "\n",
    "for pubid in network_data['pubid'].unique():\n",
    "    trust_network.add_edges_from(edges(pubid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from gensim.utils import deaccent\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "def preprocessing(line):\n",
    "    line = str(line).lower()\n",
    "    line = re.sub(r\"[{}]\".format(string.punctuation), \" \", line)\n",
    "    return deaccent(line)\n",
    "\n",
    "peer_profiles = pd.DataFrame(columns=['id', 'profile'])\n",
    "\n",
    "for pid in network_data['authid'].unique():\n",
    "    profile = preprocessing(network_data[network_data['authid'] == pid]['title'].str.cat(sep=' '))\n",
    "    peer_profiles = peer_profiles.append({'id': pid, 'profile': profile}, ignore_index=True)\n",
    "\n",
    "tfidf = TfidfVectorizer().fit_transform(peer_profiles['profile'])\n",
    "\n",
    "def content_based_recommendation(pid):\n",
    "    target_profile = tfidf.getrow(pid)\n",
    "    cosine_similarities = linear_kernel(target_profile, tfidf).flatten()\n",
    "\n",
    "    return [sorted(trust_network.nodes)[index] for index in cosine_similarities.argsort()[:-20:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import groupby\n",
    "\n",
    "alpha = 0.5\n",
    "\n",
    "recommendations = content_based_recommendation(1)\n",
    "\n",
    "centralities = {list(peer_centrality)[0]: peer_centrality[list(peer_centrality)[0]] for peer_centrality in degree_centrality(trust_network, alpha) if list(peer_centrality)[0] in recommendations}\n",
    "all_distances = [(target, path_length(sum_of_weights(jumps(p), trust_network), alpha)) for target in recommendations for p in nx.all_simple_paths(trust_network, 1, target, cutoff=6)]\n",
    "distances = {pid: min(dist)[1] for pid, dist in groupby(all_distances, key=lambda d: d[0])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centrality_recommendations = sorted(recommendations, key=lambda recommended: centralities[recommended], reverse=True)\n",
    "distance_recommendations = sorted(recommendations, key=lambda recommended: distances.get(recommended, 999), reverse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centralities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centrality_recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
